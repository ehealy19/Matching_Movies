{
  "hash": "847697af44f3342891811c3e68650b2a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Leading Ladies and Lost Revenue: A Causal Analysis of Female Representation and Box-Office Returns\"\nauthor:\n  - name: Lizzie Healy\n    corresponding: true\n    email: emh201@georgetown.com\n    roles:\n      - Project Designer\n      - Data Collector\n      - Methodologist\n      - Analyst\n      - Visualization\n    affiliations:\n      - Georgetown University\nkeywords:\n  - Films\n  - Gender Equality\n  - Economics\nabstract: |\n  This work will investigate the impact of gender bias in the film industry pertaining to economic outcomes. Specifically, it will establish a causal link between a film casting a female actress in the leading role and the resulting box-office revenue. This will be accomplished utilizing propensity weighting, which will match movies based on the perceived similarity of their characteristics. These predictor variables will include the year, season of release, genre, runtime, director and writers, star power level of the cast, MPAA rating, IMDb Metascore, IMDb Votes, number of awards won, country of release, language, film description, the production budget, the aspect ratio, the color, the countries of origin, filming locations, production companies, and tagline. To deal with the variables that are non-numeric the following steps will be taken. Firstly, a network analysis will be performed on the cast to produce a measure of centrality of the actors/actresses. Secondly, a sentiment analysis will be performed on the film description and tagline. The primary outcome variable will be the box-office number measured in US dollars, measured as the gross value worldwide. The IMDb score will be employed as an additional outcome measure to be used as a robustness check. A secondary robustness check may be employed in which the primary variable of interest will be whether the film passes the Bechdel test, indicating true female representation in the film. The initial hypothesis is that films that opt to feature a female in the leading role will experience a decrease value in the box office revenue.\nplain-language-summary: |\n  Earthquake data for the island of La Palma from the September 2021 eruption is found ...\nkey-points:\n  - A web scraping script was developed to pull data from the Instituto Geogràphico Nacional into a machine-readable form for analysis\n  - Earthquake events on La Palma are consistent with the presence of both mantle and crustal reservoirs.\ndate: last-modified\nbibliography: references.bib\ncitation:\n  container-title: Film Data Science\nnumber-sections: true\njupyter: python3\nkernel: dsan5650\n---\n\n\n## Introduction\n\n::: {#24df9362 .cell execution_count=1}\n``` {.python .cell-code .hidden}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#| label: fig-timeline\n#| fig-cap: Visual of the \n#| fig-alt: An event plot of the years of the last 8 eruptions on La Palma.\n```\n:::\n\n\n:::{#e0478066 .cell .markdown}\n### Causality\n\nMy previous paper: [Behind the Box Office: Directorial Influence on Film Revenue in the United States Entertainment Industry](./assets/thesis.pdf) attempted to analyze the link between director quality and box-office success of a film. The paper created two novel measures of director quality; a summation of all box-office revenue earned by and the director's films and the accumulated number of critical awards from the fifteen years leading up to the film in question. The main dependent variable was domestic box-office revenue and a robustness check was implemented changing the dependent variable to the IMDb rating earned. \n\n![](./assets/thesis_table1.png)\n![](./assets/thesis_table2.png)\n\nThe paper found an increase in director financial quality yielded between a 0.0289% and 0.0307% increas in domestic gross and no impact on IMDb rating. Conversely, director quality in terms of critical acclaim yielded no significant impact on domestic gross, but betweeen 0.01803 and 0.0270 point increase in IMDb rating. The paper also discovered a statistically significant decrease in domestic gross for demale directors as compared to male directors.\n\nOverall, the results were thought-provoking, however, the methodology used was lacking in the causality department. This paper, if anything, worked towards establishing a weak association due to it statical analysis going only so far as a simple ordinary-least-squares regression and controlling for confounding variables. While, the variables were considered and included in the regression equation, they were all treated equally as controls, thus a more complex analysis is warranted. \n\nFurthermore, I wanted to investigate the conclusion of gender bias further and shifted this analysis to examine actors instead of directors.\n\nMoving forward, the work to get to causality includes introducing causality instead of just controlling for all covariates.\n\nThus, this paper will investigate the impact of gender bias in the film industry pertaining to economic outcomes. Specifically, it will attempt to establish a causal link between a film casting a female actress in the leading role and the resulting box-office revenue by employing propensity score matching.\n\nNeed to argue that there is sufficient common support between the treatment and control groups in a dataset in order to use propensity scores.\n\nData collection and preparation is discussed in @sec-data.\n\nMethodology and propensity scoring is discussed in @sec-meth\n\nResults and anlysis are disucssed in @sec-results\n\nConluding remarks, limitations, and future work are discussed in @sec-conclusion\n\n## Data {#sec-data}\n\nThe data for this research was collected from separate sources: [Open Movie Database (OMDb)](https://www.omdbapi.com/) and [The Movie Database (TMDb)](https://www.themoviedb.org/). Both are sources for movie and television metadata, differing only in their sourcing and specific variables provided. OMDb partly sources from Amazon's Internet Movie Database (IMDb) and then relies on crowdsourcing for missing data, while TMDb is independently created and relies solely on crowd-sourcing from its community of film-buffs to provide data entry for films. Both of these sources offer an API that allowed for the collection of movie metadata, which was then merged using an inner join on the film Title and resulted in the following variables: Title, Year, Runtime, Budget, Released, Genre (Action, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama, Family, Fantasy, Film Noir, History, Horror, Music, Musical, Mystery, Romance, Sci-Fi, Sport, Thriller, War, Western), MPAA Rating (G, GP, M, M/PG, NC-17, Not-Rated, PG, PG-13, R, TV-MA, Unrated, Accepted), Production Companies, Director, Writer, Country, Language, Description, Tagline, Overview, Actors, Box Office, Revenue, IMDb Rating, Metascore, IMDb Votes, TMDb rating, Vote Count, Awards, and Poster URL.\n\nWith this combined dataset, some further preparation was required to move forward with the analysis. Firstly, some variables were dropped as they were deemed unimportant while others were very similar across the datasets for example only the description variable was kept and the overview variable was dropped. All missing and zero values in numerical variables were removed and each of the variables was converted to the correct data type. The release date was split into three variables for the month, day, and year. For the categorical variables two different techniques were utilized. For the genere and MPAA rating a one-hot encoding was applied. However for the language and country variables, only the first observation of each was kept and then they were categorized simply as either english or other language and domestic (for US) and international for all other countries. \n\nThe final dataset included a total of 2,816 films with 61 columns of variables. \n\nAdd in some descriptive statistics of the dataset.\n\n![](./notebooks/notebook_output/imdb_rating.png)\n\n: IMDb Rating Distribution {#tbl-1}\n\n| Variable | Minimum | Maximum | Mean | Standard Deviation |\n|-----------------|----------------------|-------------|\n| Box Office | 3,622 | 858,373,000 | 73,753,531 | 88,133,798 |\n| Budget | 7,000 | 460,000,000 | 49,601,710 | 54,138,962 |\n| Runtime | 63 | 238 | 113 | 20.6 |\n| IMDb Rating | 1.9 | 9.3 | 6.6 | 0.9 |\n| IMDb Votes | 1,672 | 3,059,994 | 222,006 | 284,492 |\n\n![](./notebooks/notebook_output/imdb_rating.png)\n\n![](./notebooks/notebook_output/imdb_overtime.png)\n![](./notebooks/notebook_output/boxoffice_overtime.png)\n\n![](./notebooks/notebook_output/genre_counts.png)\n![](./notebooks/notebook_output/rated_counts.png)\n\n![](./notebooks/notebook_output/mpaa_pie.png)\n\n\n## Methodology {#sec-meth}\n\n### Manufactured Variables\n\n#### Top Directors\n#### Top Writers\n#### Top Production Company\n\n#### Sentiment Analysis of tagline and description\n\nIn order to extract meaningful value from the film description and tagline, sentiment analysis was performed on the text. This sentiment analyis was performed by an off-the-shelf pre-trained model publically available [Hugging Face](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english). This model was trained on English text specifically for binary text classifaction and boosted a high accuracy score. The end result is a two variables with a binary value of 1 for positive sentiment or 0 for negative sentiment of both the film description and film tagline. \n\n|        Title         |        Tagline        | Tagline Sentiment |\n|---------------------- |---------------------|------------------|------------|\n| Surf's Up | A Major Ocean Picture. | 1 |\n| The BFG | The world is more giant than you can imagine. | 1 |\n| Twin Peaks: Fire Walk with Me | In a town like Twin Peaks, no one is innocent. | 0 |\n| Meet the Robinsons | If you think your family's different, wait 'til you meet the family of the future. | 1 |\n| The Royal Tenenbaums | Family isn't a word ... It's a sentence. | 0 |\n\n: Example of the Tagline Sentiment Values. {#tbl-1}\n\n| Sentiment | Count |\n|---------------------- |---------------------|\n| Positive | 1476 |\n| Negative | 1340 |\n\n: Count of positive and negative sentiment. {#tbl-1}\n\n#### Creation of the starpower variable\n\nOne of the most important building blocks of a film is the cast of actors and actresses and well-known names can be a huge draw to the theatres to movie-goers. This feature seemingly has an impact on the outcome of the film and its financial success. Thus, finding a way to classify the 'starpowerness' of the cast was paramount to this analysis. The dataset, unfortunately, only provides the three main cast members, which discounts films that rely on an ensemble cast or have a large enough budget to cast many big-names. That being said, this research attempted to define a metric that quantified this 'starpower' aspects of the three cast members, in the hopes that the success and name-recognition can be at least partly captured.\n\nThe metric was created by the collecting lists of A-list and B-list actors and actresses. In film-terms these categorization reflect how 'bankable' the stars are or how many financial draw they bring to a film theoretically. These lists are all collected from IMDb and included a wide-range of household names. With these lists, the cast variable was split into actor1, actor2, actor3 based simply on the order in which they were listed. Then, each of the cast variables were referenced against all three of the lists. The film title received:\n\n1. **2 points** if a cast member was part of the A-list\n2. **1 point** if cast member was part of the B-list\n\nThese points were added in the `starpower` variable and then divided by three to get a finalized score of the points across the three cast members. @tbl-5 shows an example of the scoring.\n\n|        actor1         |        actor2        |      actor3      | starpower  |\n|---------------------- |---------------------|------------------|------------|\n| Mark Wahlberg         | Tyrese Gibson       | André 3000       | 0.666667   |\n| Jamie Bell            | Andy Serkis         | Daniel Craig     | 1.333333   |\n| Ryan Reynolds         | Blake Lively        | Peter Sarsgaard  | 0.333333   |\n| Marc Singer           | Tanya Roberts       | Rip Torn         | 0.000000   |\n| Tom Hiddleston        | Samuel L. Jackson   | Brie Larson      | 1.000000   |\n| Jeremy Renner         | Ed Helms            | Jake Johnson     | 0.000000   |\n| Frankie Muniz         | Amanda Bynes        | Paul Giamatti    | 1.000000   |\n| Ben Barnes            | Skandar Keynes      | Georgie Henley   | 0.000000   |\n| Jason Bateman         | Charlie Day         | Jason Sudeikis   | 1.000000   |\n| Jack Black            | Ana de la Reguera   | Héctor Jiménez   | 0.333333   |\n\n: Starpower metric scores for actors in 10 movies. {#tbl-5}\n\n[IMDb A-list Actors](https://www.imdb.com/list/ls056262001/)\n[IMDb A-list Actresses](https://www.imdb.com/list/ls056262192/)\n[IMDb B-list](https://www.imdb.com/list/ls024783564/)\n\n\n#### Creation of the variable that indicates female in leading role\n\nThis analysis relied on the ability to distinguish between female and male leading actresses and actors, however, this is not something directly encoded into the metadata of a film, thus this variable had to be manufactured. In order to achieve this, a list of all current female actresses was collected from [Wikipedia](https://en.wikipedia.org/wiki/List_of_American_film_actresses). This list included 2,816 names of female actresses, alphabetized. To note, there was attempts to utilize a list of all female names and an off-the-shelf model to guess whether the cast member listed identified a male of female, however, both of these methods produced increased inaccuracy, thus the list of female actresses method was proceeded with.\n\nThe next step was to determine only the presumed lead cast member by extracting the first person listed in the 'Actors' variable of the dataset. This name was then compared against the list from of female actresses and received a value of 1 if the cast member was included on the list. \n\nTherefore, the end result was a variable titled 'female_lead' if the first cast member listed in the IMDb metadata was a member of the current working female actress list and a 0 if the cast member was not a member of the list and, thus, presumably a male actor. @tbl-1 displays an example of the accuracy results of this variable.\n\n\n| Title           | First Actor           | Female Lead |\n|-----------------|----------------------|-------------|\n| The Family      | Robert De Niro       | 0           |\n| The Shack       | Sam Worthington      | 0           |\n| The Dead Zone   | Christopher Walken   | 0           |\n| The Ref         | Denis Leary          | 0           |\n| Flyboys         | James Franco         | 0           |\n| ATL             | Tip 'T.I.' Harris    | 0           |\n| Like a Boss     | Tiffany Haddish      | 1           |\n| Enemy Mine      | Dennis Quaid         | 0           |\n| Proud Mary      | Taraji P. Henson     | 1           |\n| Valmont         | Colin Firth          | 0           |\n\n: Example of the 'female_lead' variable {#tbl-1}\n\nAs displayed in @tbl-2 the films were split between 488 films with female leading actresses and 2328 films with male leading actors.  \n\n| Name                | Year |\n|---------------------|------|\n| Female Leads    | 488 |\n| Male Leads      | 2328 |\n\n: Male versus Female Director {#tbl-2}\n\n### Propensity score matching\n\nStandardScaler\nPropensity scores calculated\n\ninternational excluded\nother language excluded\nmusical genre excluded\naccepted mpaa rating excluded\n\n### Robustness Checks\n\nImplemented the IMDb score as the outcome variable as a robustness check \\\nDoes a female in the lead role impact the critical success of the film?\n\n## Results {#sec-results}\n\n### Box Office Results\n\nFemale-lead had higher box-office average\n\n### IMDb Rating Results\n\nFemale-lead had lower IMDb scores\n\n| Gender of Lead Role     | Box Office | IMDb Rating |\n|---------------------|------|------|\n| Female             | 62,708,871.36 | 6.329 |\n| Male               | 61,076,707.45 | 6.601 |\n\n## Conclusion {#sec-conclusion}\n\n### Limitations:\n1. More data\n2. Network Analysis\n3. Robustness Checks with Bechdel test\n4. Inacurracy from matching female leads & first actor not always the lead\n5. Unbalanced Dataset (is this an issue?)\nFurther Work:\n1. classify the tagline and description\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n:::\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}